# 谈谈你对HTTP协议的理解

* [谈谈你对HTTP协议的理解](#谈谈你对http协议的理解)
  * [1 HTTP/0\.9](#1-http09)
    * [1\.1 特点](#11-特点)
    * [1\.2 具体功能](#12-具体功能)
    * [1\.3 缺点](#13-缺点)
  * [2 HTTP/1\.0](#2-http10)
    * [2\.1 特点](#21-特点)
    * [2\.2 主要新增变化](#22-主要新增变化)
      * [2\.2\.1 请求格式](#221-请求格式)
      * [2\.2\.2 回应格式](#222-回应格式)
      * [2\.2\.3 Content\-Type 字段](#223-content-type-字段)
      * [2\.2\.4 Content\-Encoding 和 Accept\-Encoding](#224-content-encoding-和-accept-encoding)
      * [2\.2\.5 Content\-Length 字段](#225-content-length-字段)
    * [2\.3 缺点](#23-缺点)
  * [3 HTTP/1\.1](#3-http11)
    * [3\.1 特点](#31-特点)
    * [3\.2 主要新增变化](#32-主要新增变化)
      * [3\.2\.1 持久连接](#321-持久连接)
      * [3\.2\.2 管道机制](#322-管道机制)
      * [3\.2\.3 详解管道机制（为什么一般不开 pipelining）](#323-详解管道机制为什么一般不开-pipelining)
      * [3\.2\.4 复用 TCP 可能会导致乱序吗？](#324-复用-tcp-可能会导致乱序吗)
      * [3\.2\.5 再提 Content\-Length 字段](#325-再提-content-length-字段)
      * [3\.2\.6 分块传输编码](#326-分块传输编码)
      * [3\.2\.7 其他功能](#327-其他功能)
    * [3\.3 缺点](#33-缺点)
  * [4 SPDY 协议](#4-spdy-协议)
  * [5 HTTP/2](#5-http2)
    * [5\.1 二进制协议](#51-二进制协议)
    * [5\.2 多工](#52-多工)
    * [5\.3 数据流](#53-数据流)
    * [5\.4 头信息压缩](#54-头信息压缩)
    * [5\.5 服务器推送](#55-服务器推送)
    * [5\.6 数据流优先级](#56-数据流优先级)
  * [6 举例，简述各本的区别](#6-举例简述各本的区别)
    * [6\.1 HTTP/1\.0](#61-http10)
    * [6\.2 HTTP/1\.1 使用 Pipelining](#62-http11-使用-pipelining)
    * [6\.3 HTTP/2 Multiplexing](#63-http2-multiplexing)

参考：https://www.ruanyifeng.com/blog/2016/08/http.html

毫无疑问，Web 性能的终极目标是减少到用户端的延迟，让用户能够尽快的打开前端网页并进行相关交互。

Web 性能则取决于以下几点：
> 1. 客户端渲染性能。
> 2. 服务端处理请求的性能。
> 3. 客户端请求、服务端回应的传输性能。

对于传输性能，我们希望在实现业务的前提下，做到以下几点：

> 1. 客户端发送尽可能少的数据。
> 2. 服务端回应尽可能少的数据。
> 3. 尽可能减少请求次数，减少往返的次数。

为了做到这几点，我们希望能有一个传输协议，只要客户端和服务端都去遵守，就能实现好的传输效果。

这就是 HTTP 协议的由来。随着日益增长的 Web 需求，现代 Web 技术对性能的要求越来越高，这就要求 HTTP 不断改善，提升效率。

## 1 HTTP/0.9

HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。

### 1.1 特点

> 1. 只支持`GET`命令。
> 2. 服务器只能回应HTML格式的字符串。
> 3. 如果请求的页面不存在，不会返回任何错误码。
> 4. 服务器发送完毕，就关闭TCP连接。

### 1.2 具体功能

最早的HTTP协议版本是1991年发布的 HTTP/0.9。该版本极其简单，只有一个命令`GET`。

```js
GET /index.html
```

上面命令表示，TCP 连接（connection）建立后，客户端向服务器请求（request）网页`index.html`。

**协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。**如果请求的页面不存在，也不会返回任何错误码。

服务器发送完毕，就关闭TCP连接。

### 1.3 缺点

缺点就是功能过于单一，过于简单，对于一些基本的需求难以支持。

## 2 HTTP/1.0

1996年5月，HTTP/1.0 发布，内容大大增加。

### 2.1 特点

> 1. 任何格式的内容都可以发送。这使得互联网不仅可以传输文字，还能传输图像、视频、二进制文件。这为互联网的大发展奠定了基础。
>
> 2. 除了`GET`命令，还引入了`POST`命令和`HEAD`命令，丰富了浏览器与服务器的互动手段。
> 
> 3. HTTP请求和回应的格式也变了。除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。头信息对内容是一种补充描述，指导客户端和服务器对内容进行操作。
>
> 4. 其他的新增功能还包括状态码机制（status code）、多字符集支持、多部分发送（multi-part type）、权限（authorization）、缓存（cache）、内容编码（content encoding）等。

### 2.2 主要新增变化

#### 2.2.1 请求格式

下面是一个 HTTP/1.0 的请求的例子。

```js
GET / HTTP/1.0
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
Accept: */*
```

可以看到，这个格式与 HTTP/0.9 有很大变化。

第一行是请求命令，必须在尾部添加协议版本（`HTTP/1.0`）。后面就是多行头信息，描述客户端的情况。

#### 2.2.2 回应格式

服务器的回应如下。

```js
HTTP/1.0 200 OK 
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84

<html>
  <body>Hello World</body>
</html>
```

回应的格式是"头信息 + 一个空行（`\r\n`） + 数据"。其中，第一行是"协议版本 + 状态码（status code） + 状态描述"。

#### 2.2.3 Content-Type 字段

关于字符的编码，HTTP 1.0 规定，头信息必须是 ASCII 码，后面的数据可以是任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，这就是`Content-Type`字段的作用。

比较常见的`Content-Type`字段：

> 1. text/html
> 2. image/jpeg
> 3. application/zip
> 4. .....

这些数据类型总称为``MIME type，每个值包括一级类型和二级类型，之间用斜杠分隔。

除了预定义的类型，厂商也可以自定义类型。比如发送的是Debian系统的二进制数据包：

```js
application/vnd.debian.binary-package
```

`MIME type`还可以在尾部使用分号，添加参数。发送的是网页，而且编码是UTF-8:

```js
Content-Type: text/html; charset=utf-8
```

客户端请求的时候，可以使用Accept字段声明自己可以接受哪些数据格式。客户端声明自己可以接受任何格式的数据:

```js
Accept: */*
```

`MIME type`不仅用在HTTP协议，还可以用在其他地方，比如HTML网页:

```js
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<!-- 等同于 -->
<meta charset="utf-8" /> 
```

#### 2.2.4 Content-Encoding 和 Accept-Encoding

由于发送的数据可以是任何格式，因此可以把数据压缩后再发送。

客户端在请求时，用`Accept-Encoding`字段说明自己可以接受哪些压缩方法:

```js
Accept-Encoding: gzip, deflate
```

如果支持请求中的压缩方法，服务端可以把body按照gzip方法压缩，并且在响应头中带上`Content-Encoding`：

```js
Content-Encoding: gzip
```

客户端收到响应后，可以根据`Content-Encoding`指导的方法解压缩body，拿到内容。

#### 2.2.5 Content-Length 字段

在客户端和服务端建立TCP连接之后，客户端需要先向服务端发送请求，此时服务端得知道请求的边界，也就是客户端的请求是否发送完成。

对此，在 HTTP/1.0 中，客户端发送HTTP请求时，需要再Header中带上`Content-Length`，告知服务端我这个请求的长度，读完数据就是请求的结束。

```js
Content-Length: 3495
```

上面代码告诉浏览器，本次请求的长度是3495个字节，后面的字节就属于下一个请求了。

同理，服务端处理完请求后，将响应客户端。一般情况下，当服务器完成请求处理后会立即断开TCP连接。当客户端知道TCP连接断开了，也就知道响应已经读完了。所以响应头中的`Content-Length`不是必须的。

有些同学可能要问了，为啥响应可以通过关闭TCP告知，但是请求不能通过关闭TCP告知呢？

很简单，TCP连接都关了，服务端当然知道你请求完毕了，但是也没有办法响应客户端了。

### 2.3 缺点

HTTP/1.0 的主要缺点是，每个TCP连接只能处理一个请求，当服务器完成请求处理后立即断开TCP连接。如果还要请求其他资源，就必须再新建一个连接。

TCP连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。所以，HTTP 1.0 的性能比较差。随着网页加载的外部资源越来越多，这个问题就愈发突出了。

为了解决这个问题，有些浏览器在请求时，用了一个非标准的`Connection`字段：

```js
Connection: keep-alive
```

这个字段要求服务器不要关闭TCP连接，以便其他请求复用。服务器同样回应这个字段。

```js
Connection: keep-alive
```

一个可以复用的TCP连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段，不同实现的行为可能不一致，因此不是根本的解决办法。

因为这个拓展非常实用，所以HTTP/1.1直接将其收录为新一代特性。

**(注意，虽然有些客户端和服务端都支持长连接，但是这个特性并不在HTTP/1.0中规定)**

## 3 HTTP/1.1

1997年1月，HTTP/1.1 发布，只比 HTTP/1.0 晚了半年。它进一步完善了 HTTP 协议，一直用到了20年后的今天，直到现在还是最流行的版本。

### 3.1 特点

> 1. 持久连接。
> 2. 管道机制。
> 3. Content-Length。
> 4. 分块传输编码。
> 5. 其他的新增功能，包括新的交互方式，比如`PUT`、`DELETE`；客户端请求新增了`Host`字段，用于指定服务器的域名。

### 3.2 主要新增变化

#### 3.2.1 持久连接

HTTP/1.1 的最大变化，就是引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明`Connection: keep-alive`。

客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送`Connection: close`，明确要求服务器关闭TCP连接。

#### 3.2.2 管道机制

HTTP/1.1 引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。

举例来说，客户端需要请求两个资源。

> 1. 以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。
>
> 2. 管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。这样处理是为了顺序对应，防止出现乱序。

#### 3.2.3 详解管道机制（为什么一般不开 pipelining）

非常推荐看看这个回答：https://www.zhihu.com/question/340651010/answer/789344104

> HTTP/1.1 是基于TCP的协议，TCP模型是双向数据流，任何在一个TCP连接上处理超过一个请求的协议都需要解决这样两个问题：
>
> 1. 分片：如何将流中的多个请求和响应拆分成独立的消息。
> 2. 对应：如何将请求和响应对应起来。
>
> HTTP/1.1的方案中，请求和响应的消息必须在流中占据一段连续的空间，它的格式保证解析方能正确判断出消息体的长度，而请求和响应的对应关系采取自然顺序，第一个对应第一个，第二个对应第二个（排除返回Status 1xx的情况）。
>
> **简单来说，就是第一个请求全发完才能发第二个，响应也是。**
>
> 最传统的 HTTP/1.1 Server 在每个连接上的工作模式是读取请求（头）、解析请求、处理请求、发送结果四个步骤的循环，而且每个步骤都是阻塞的。
>
> 这其中，第一步和第四步是IO密集的工作，而第二步和第三步是CPU密集的工作，这就意味着服务器忙着IO的时候CPU在放假，忙着CPU计算的时候IO在偷懒，不利于降低响应延迟和提高服务器整体效率。
>
> 解决的方案是让这四个步骤重叠起来，负责读取请求的部分读取完上一个请求（包括请求头和body）之后，立即读取下一个请求；负责解析请求的部分实现一边读取一边解析；负责处理请求的部分在处理完上一个请求之后立即继续处理下一个请求，无需等待结果完全发送完成。
>
> 这样整体请求处理的延迟就可以降低，IO和CPU的操作可以重叠起来。
>
> 更进一步，这四步操作中往往处理请求的步骤是最耗时的，如果进一步让上一个请求还没有处理完的情况下，就允许下一个请求进入处理阶段，这样就可以通过并行处理多个请求进一步降低延迟，这个设置一般叫做pipeline深度。
>
> 增大pipeline深度虽然可能一定程度上降低延迟，但有**同一个连接上的请求的实际执行顺序与输入顺序不同的风险**，因而一般默认是不开启的。

（关于这里的“同一个连接上的请求的实际执行顺序与输入顺序不同的风险”，我认为取决于执行速度，假如输入顺序是A、B，先处理A，在A未处理完之前继续处理B，B先于A处理完，就会先于A执行，这就导致一些需要顺序执行的操作发生错误）

> 读取请求、解析请求的部分则一般没有限制，如果一次发送大量的不含消息体的请求，读取请求的部分可以在一次系统调用中将这些数据全部读回，对HTTP服务的性能也有一定帮助。
>
> 这些实现和调用 HTTP/1.1 服务的技术统称pipelining，它实际上也不是 HTTP 独有的技术，而是许多协议上都可以使用的。

#### 3.2.4 复用 TCP 可能会导致乱序吗？

有些同学可能要问了，前面你举了个例子是：

> 管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。

那么，有没有可能出现乱序的情况呢：

> 1. 客户端按照A、B、C的顺序，同时发出请求。
> 2. 经过 TCP 的传输，A出现延迟，服务端收到了B、C。
> 3. 最终，服务端收到的顺序是B、C、A，响应的顺序也是B、C、A。

我个人也曾经被这个问题绕进去了，但是只要学好计算机网络，就知道不会出现这种情况。

HTTP 请求的传输依靠 TCP，数据都是首先提交到 TCP 流，再由 TCP 流发送到对端的，当数据提交到 TCP 流的时候，它传输的顺序就已经完全确定了。

也就是说，你把 HTTP 请求提交给 TCP 去处理，你提交的顺序是A、B、C，如果传输过程没有出错，那么服务端收到的顺序也一定是A、B、C（而且是必须保证传输顺序，不然没有意义）。

> 1. 因为是同时发出A、B、C请求，HTTP 生成这三个请求报文后交给 TCP，TCP 会按照顺序打好 n 个数据包（假设为1、2、3包），然后通过 TCP 连接开始传输。
>
> 2. 假如传输过程中，1包被阻塞在半路（延迟）。服务端收到2、3包后，会先缓存起来，并且回应两个2、3包的ack。客户端久久等不到服务端对1包的ack，就会重发1包。
>
> 3. 同理，假如传输过程中1包丢了（丢包），也会像延迟那样处理。
>
> 4. 总之，用各种手段把包拿齐之后，服务端从包中重组出 HTTP 请求，再根据请求报文的固定格式进行解析，如果数据正确就可以顺序解析出A、B、C三个请求报文。

#### 3.2.5 再提 Content-Length 字段

这个问题是随着持久连接出现的。

在 HTTP/1.0 时代，我们怎么知道一个请求/响应是否传输完成了呢？

> 1. 请求需要带上请求头`Content-Length`，告知服务端请求的长度，读完就是一个请求传输完成。
>
> 2. 服务端响应完毕后会关闭TCP，客户端就知道这个传输已经完成了，收到的数据包都全了。

但是在 HTTP/1.1，TCP连接支持复用，不会很快关闭，那我们怎么知道一个请求/响应是否传输完成了呢？

> 1. 请求还是不变，需要带上`Content-Length`。
>
> 2. 服务端响应完毕后不关闭TCP，在响应中带上响应头`Content-Length`，告知客户端响应的长度，读完就是响应传输完成。

对`Content-Length`的处理必须要特别小心：

> 1. `Content-Length` > 实际长度。如果Content-Length大于实际长度, 服务端/客户端读取到消息结尾后, 会等待下一个字节, 自然会无响应直到超时。
>
> 2. `Content-Length` < 实际长度。如果Content-Length小于实际长度, 首次请求的消息会被截取。假如此时再收到下一个请求，那么截断的后半部分会被拼到下一个请求中，导致解析失败。

#### 3.2.6 分块传输编码

使用`Content-Length`字段的前提条件是，服务器发送回应之前，必须知道回应的数据长度。

但是对于一些很耗时的动态操作来说，这意味着，服务器要等到所有操作完成，才能发送数据，显然这样的效率不高。

更好的处理方法是，产生一块数据，就发送一块，采用"流模式"（stream）取代"缓存模式"（buffer）。

因此，HTTP/1.1 规定可以不使用`Content-Length`字段，而使用"分块传输编码"（chunked transfer encoding）。只要请求或回应的头信息有Transfer-Encoding字段，就表明回应将由数量未定的数据块组成：

```js
Transfer-Encoding: chunked
```

每个非空的数据块之前，会有一个16进制的数值，表示这个块的长度。最后是一个大小为0的块，就表示本次回应的数据发送完了。

```js
HTTP/1.1 200 OK
Content-Type: text/plain
Transfer-Encoding: chunked

25
This is the data in the first chunk

1C
and this is the second one

3
con

8
sequence

0
```

如果一直没读到结束，且TCP连接依然保持，那客户端会继续等待服务端的响应。但是如果在响应完毕之前TCP就断开了，客户端应该认为响应失败，该次HTTP请求发生了错误。

#### 3.2.7 其他功能

HTTP/1.1 还新增了许多动词方法：`PUT`、`PATCH`、`HEAD`、 `OPTIONS`、`DELETE`。

另外，客户端请求的头信息新增了`Host`字段，用来指定服务器的域名。根据规范，HTTP/1.1 的请求必须有`Host`请求头，否则服务端可能会认为是非法请求，返回400错误。

```js
Host: www.example.com
```

有了`Host`请求头，就可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础。

虚拟主机（virtual hosting）即共享主机（shared web hosting），可以利用虚拟技术把一台完整的服务器分成若干个主机，因此可以在单一主机上运行多个网站或服务。

举个例子：

有一台 ip 地址为 61.135.169.125 的服务器，在这台服务器上部署着谷歌、百度、淘宝的网站（同IP下有多个站）。为什么我们访问 https://www.google.com 时，看到的是 Google 的首页而不是百度或者淘宝的首页？原因就是`Host`请求头决定着访问哪个虚拟主机。

### 3.3 缺点

最大的效率问题是“队头阻塞”。

> “队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。
>
> “队头阻塞”和pinelining也无关，就算同时发出A、B、C请求，服务端也得按照A、B、C请求的顺讯进行响应。假如A处理时间需要10s，B、C处理时间需要1s，很显然B、C会更早处理完。但是B、C还是得等候A，并且按照A、B、C请求的顺讯进行响应。
>
> 因为 HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。
>
> 队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理
>
> 如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。

为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这导致了很多的网页优化技巧，比如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等等。

## 4 SPDY 协议

2009年，谷歌公开了自行研发的 SPDY 协议，主要解决 HTTP/1.1 效率不高的问题。

这个协议在Chrome浏览器上证明可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。

## 5 HTTP/2

2015年，HTTP/2 发布。它不叫 HTTP/2.0，是因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。

### 5.1 二进制协议

HTTP/1.1 的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。

HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。

怎么做到的呢？

> HTTP/2 在应用层与传输层之间增加一个二进制分帧层，以此达到在不改动 HTTP 的语义，HTTP 方法、状态码、URI 及首部字段的情况下，突破 HTTP/1.1 的性能限制，改进传输性能，实现低延迟和高吞吐量。
>
> 在二进制分帧层上，HTTP/2.0 会将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中 HTTP1.x 的首部信息会被封装到 Headers 帧，而我们的 request body 则封装到 Data 帧里面。

二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。

### 5.2 多工

HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。

举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分，接着回应B请求，完成后，再发送A请求剩下的部分。

这样双向的、实时的通信，就叫做多工（Multiplexing）。

### 5.3 数据流

因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

HTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID一律为奇数，服务器发出的，ID为偶数。

数据流发送到一半的时候，客户端和服务器都可以发送信号（`RST_STREAM帧`），取消这个数据流。HTTP/1.1 取消数据流的唯一方法，就是关闭TCP连接。这就是说，HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。

客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。

### 5.4 头信息压缩

HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如`Cookie`和`User Agent`，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。

HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用`gzip`或`compress`压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

### 5.5 服务器推送

HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。

常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。

其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，比如页面相关的logo，CSS，所以就主动把这些静态资源随着网页一起发给客户端了。

### 5.6 数据流优先级

由于请求可以并发发送了，那么如果出现了浏览器在等待关键的 CSS 或者 JS 文件完成对页面的渲染时，服务器却在专注的发送图片资源的情况怎么办呢？

HTTP/2.0 对数据流可以设置优先值，这个优先值决定了客户端和服务端处理不同的流采用不同的优先级策略。

## 6 举例，简述 HTTP 协议各版本的区别

参考：https://www.zhihu.com/question/340651010/answer/801471856

假设现在浏览器只能建立了一个TCP连接，上层有3个HTTP请求需要处理。3个请求和耗时（服务端处理时间，先忽略网络延迟）分别是:

```js
GET /a ：2s
GET /b ：1s
GET /c ：3s
```

### 6.1 HTTP/1.0

发送一个请求并且得到响应后再发第二个。这时，浏览器处理这3个请求的时间线：

```js
第0秒：发送GET /a。
第1秒：等待...
第2秒末：得到a的响应，发送GET /b。
第3秒末：得到b的响应，发送GET /c。
第4秒：等待...
第5秒：等待...
第6秒末：得到c的响应，共计6秒。
```

### 6.2 HTTP/1.1 使用 Pipelining

可以一次性的发送多个请求，但是服务器响应时会严格按照接收到的请求顺序依次的响应。这时，浏览器处理这三个请求的时间线（最佳状态）：

```js
第0秒：发送GET /a，GET /b , GET /c。
第1秒：等待...
第2秒末：依次a，b的响应（b虽然再第1秒末的时候已经处理完，但是由于排在前面的a还未处理完成，故而服务器是会等到a处理完后再响应b）。
第3秒末：得到c的响应。共计3秒。
```

### 6.3 HTTP/2 Multiplexing

客户端可以同时发送多个请求（每个请求被拆分成多个被编号的Frame），服务端也可同时响应多个请求。这时，浏览器处理这3个请求的时间线：

```js
第0秒：发送GET /a，GET /b , GET /c。
第1秒末：得到b的响应。
第2秒末：得到a的响应。
第3秒末：得到c的响应。共计3秒。
```

可以看到处理请求的效率是逐渐在提高的。
