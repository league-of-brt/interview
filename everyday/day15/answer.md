# 谈论一下你对mysql redo log的理解？

参考：https://zhuanlan.zhihu.com/p/93131864

## 1 从硬盘开始

mysql是基于硬盘的数据库，所以很多优化都是基于硬盘的瓶颈来做的，为了更好的理解，先花点时间回忆下硬盘的知识。

目前主流的硬盘有2种，一种是机械硬盘，一种是固态硬盘。

大家知道，在一般情况下，固态硬盘读写速度比机械硬盘块，而且快很多，那么快的原因是什么呢？ 主要跟他们的构造和工作原理有关。

### 1.1 机械硬盘

因为我们主要讨论mysql在机械硬盘条件下的表现，所以放上一张示意图：

![pic](https://brt-1303999354.cos.ap-shanghai.myqcloud.com/disk.jpg)

> 机械硬盘主要由：转轴、磁头、盘片（也称为磁盘）组成，一块硬盘中有多个盘片，一个盘片上划分了很多个磁道，每个磁道上又进一步分了扇区。
> 
> 其中扇区是实际存储数据的地方，一个扇区的大小是512个字节，当对机械硬盘进行读写时需要经过三个步骤：
> 1. 定位到磁道。
> 2. 等待旋转到对应扇区。
> 3. 开始读写。

其中步骤1，2的定位操作都是机械定位。机械硬盘的读写会比较耗时，和其机械定位的工作原理有很大的关系。

### 1.2 硬盘的读写基本单位是什么？

> 读写基本单位是扇区。盘片的原理，物理实现，磁盘控制器是按照扇区这个单位读取等操作数据的。

### 1.3 什么是扇区？

下图显示的是一个盘面:

![pic](https://brt-1303999354.cos.ap-shanghai.myqcloud.com/diskinside.png)

> 盘面中一圈圈灰色同心圆为一条条磁道，从圆心向外画直线，可以将磁道
> 划分为若干个弧段，每个磁道上一个弧段被称之为一个扇区（图践绿色部分）。
>
> 扇区是盘片的最小组成单元，通常是512字节。（由于不断提高盘片的大小，部分厂商设定每个扇区的大小是4096字节）。

### 1.4 固态硬盘

关于固态硬盘，这里只是稍微提一下。

> 固态硬盘主要由电路，闪存芯片组成，其中闪存芯片是实际存储数据的地方。
>
> 对固态硬盘的读写分两步：
>
> 1. 定位到闪存芯片。
> 2. 开始读写。

其中步骤1的定位是电子定位。

电子定位肯定比机械定位的速度要快，这也是固态硬盘读写速度快的主要原因。如果需要mysql有更高的读写性能，有条件可以考虑更换SSD。

## 2 文件系统

硬盘底层是底层硬件，写程序的时候也接触不到，我们更多是与文件系统打交道。

有人说过一句的名言：“计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决”。文件系统，对于硬盘和上层应用程序来说就是这个中间层，那么这个中间层解决了什么问题呢？

主要就一个：扇区变块（注意这里块是相对于文件系统而言的，是一个虚拟概念，硬盘并不知道什么叫块）。

### 2.1 什么是块？

> 操作系统与硬盘之间交流的最小单位就是块，它是一个虚拟的概念。是对于操作系统（软件）来说有意义的概念。
>
> 由于扇区的数量比较小，数目众多在寻址时比较困难（或者说机械寻址次数太多），所以操作系统就将相邻的扇区组合在一起，形成一个块，再对块进行整体的操作。
>
> 操作系统忽略对底层物理存储结构的设计。通过虚拟出来块的概念，在系统中认为块是最小的单位。

### 2.2 块与扇区的大小关系

> 既然块是一个虚拟概念。是操作系统自己“杜撰”的。软件的概念，不是真实的。所以大小由操作系统决定，操作系统可以配置一个块多大。一个块大小 = 一个扇区大小 * 2的n次方。N是可以修改的。

在（Linux）默认情况下：
1. 1扇区 = 512B。
2. 1block = 8扇区。
3. 1block = 8 * 512B = 4KB

实际上block = 几个扇区，是可以进行设置的，1block = 8扇区是Linux下的默认情况。

### 2.3 为什么需要块？

假设现在要往硬盘写入1M的数据，如果直接操作扇区，因为一个扇区只能容纳512B的容量，那么一共需要：1024 * 1024 / 512 = 2048，一共需要2048次机械定位。

但是，如果操作块，一共需要：1024 * 1024 / (518 * 8) = 256，一次机械定位就能写8块的扇区，相当于效率提升了8倍。

但是，因为人为划分了块的大小为4KB，对于一些较小的文件（比如只有1KB），还是会占据一块的单位。对于硬盘来说，就是8块连续的扇区只使用了其中2块，这就造成了磁盘碎片，空间利用率就降低了。

但是要记住一句话：在计算机世界计算资源是最稀缺的，时间效率是最宝贵的，储存是最不值钱的。因此为了效率，肯定要牺牲储存资源。

### 2.4 磁盘碎片和文件碎片？

两个碎片不是同一个东西。

磁盘碎片是因为文件太小，没办法完全利用块导致的。磁盘碎片纯粹是浪费了磁盘空间。

文件碎片一般是一个大文件在盘片上无法连续储存，只能碎片化储存导致的。如果存在文件碎片，读写一个文件需要多次寻址，导致读写效率低。

如果想了解更多关于文件碎片的知识，可以参考：https://www.zhihu.com/question/21554450

### 2.5 随机读写和顺序读写

我们使用文件系统，有两种方式：
1. 随机读写（默认情况）。
2. 顺序读写。

#### 2.5.1 随机读写

假设现在需要把一个15kb的文件A存在磁盘上。按照一块为4kb，需要占用4个块。

写文件A：
1. 申请到4个块，01、05、07、09。
2. 磁头定位01，写块。
3. 磁头定位05，写块。
4. .....
5. 在文件的inode元数据区，记录文件的存储位置。

```
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|ADDR|00|01|02|03|04|05|06|07|08|09|0A|0B|0C|0D|0E|0F|10|11|12|13|14|
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|DATA|  |A0|  |  |  |A1|  |A2|  |A3|  |  |  |  |  |  |  |  |  |  |  |
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
```

读文件A：
1. 文件的inode元数据区，读取文件储蓄位置。
2. 磁头定位，读01的A0。
3. 磁头定位，读05的A1。
4. 磁头定位，读07的A2。
5. 磁头定位，读09的A3。

通过对读写过程的分析我们知道，随机读写模式，空间分配策略是按需分配，要多少就分配多少。

但是分配的块之间可能不是连续的，由于不是连续的，磁头需要频繁切换，这是随机读写模式的瓶颈。

#### 2.5.2 顺序读写

假设现在需要把一个15kb的文件A存在磁盘上，按照一块为4kb，需要占用4个块。

写文件A：
1. 申请到连续的4个块，01、02、03、04。
2. 磁头定位01，写块。
3. 磁头定位02，写块。
4. .....
5. 在文件的inode元数据区，记录文件的存储位置。

```
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|ADDR|00|01|02|03|04|05|06|07|08|09|0A|0B|0C|0D|0E|0F|10|11|12|13|14|
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|DATA|  |A0|A1|A2|A3|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
```

这里的区别是，需要预先分配磁盘空间。如果没有连续的磁盘空间，可能会写失败。

读文件A：
1. 文件的inode元数据区，读取文件储蓄位置。
2. 磁头定位，读01的A0。
3. 磁头定位，读02的A1。
4. .....

实际上，因为块是连续的，解决了磁头定位的问题，所以读写效率都比随机读写要高得多。

但是顺序读写有两个前提：
1. 文件大小是固定的。
2. 预先分配磁盘空间。

对于前提1，我是这样理解的：

现在文件A已经占用了A0-A3块，那么磁盘可能还会写入文件B，占用05-07块：

```
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|ADDR|00|01|02|03|04|05|06|07|08|09|0A|0B|0C|0D|0E|0F|10|11|12|13|14|
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|DATA|  |A0|A1|A2|A3|B0|B1|  |  |  |  |  |  |  |  |  |  |  |  |  |  |
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
```

现在A文件是15kb，我想将其拓展为21kb，这就需要额外的两个块。

在写A文件之前，会去先申请磁盘空间，结果发现A3后面已经被占用，会申请失败。如果你实在是想要更新A文件，可以在A0-A3的基础上去复写。

对于前提2，我是这样理解的：

我想写21kb的文件C，但是这块磁盘上大部分的空间已经被占用了：

```
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|ADDR|00|01|02|03|04|05|06|07|08|09|0A|0B|0C|0D|0E|0F|10|11|12|13|14|
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|DATA|  |..|..|..|..|..|..|  |..|  |  |  |..|  |  |..|  |  |..|  |..|
+----+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
```

写之前我先去申请磁盘空间，结果发现已经没有一块连续的空间能写入C了，会导致写入失败。

#### 2.5.3 性能差距

根据硬件的实际情况可能不同。一般情况下，相同硬件，顺序读写性能甚至能达到随机读写的几百倍。如果需要操作硬盘，并且满足顺序读写条件，一般建议使用顺序读写。

在固态硬盘上，差距没那么夸张，但还是有几倍的差距。

## 3 操作系统

从上面的知识点，我们可以知道磁盘的性能是比较差的。如果操作系统随便允许各种软件去直接读写磁盘，那么读写请求一多，磁盘io就会成为瓶颈，性能就会变差。

操作系统肯定不想看到这种事情发生，读写一多系统就炸裂，那肯定没人用了，必须对这种情况做优化处理。

### 3.1 对磁盘读写的优化

大家都知道内存读写快，磁盘读写慢，那么直接用内存给磁盘操作面前加一道缓存。

![pic](https://brt-1303999354.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20210216002941.png)

> linux为了保证系统的安全，按照运行空间，分了内核空间和用户空间。
>
> 文件系统运行在内核空间，上层应用程序运行在用户空间，为了提高文件的操作操作，上层应用并不直接操作磁盘，而是先写到文件buffer（一块内存），buffer的内容按照一定的策略异步刷新到磁盘。
> 
> 文件的写入过程默认是异步的，又叫延迟写。 
>
> 读的时候先读cache，cache读不到再去磁盘上读，这跟我们的用redis差不多，先读redis，读不到再去读库。

### 3.2 磁盘的异步刷新策略

我查了一下，关于磁盘的异步刷新策略，有三种：
> 1. flush每隔5秒执行一次。
> 2. 内存中驻留30秒以上的脏数据，将由flush在下一次执行时写入磁盘。
> 3. 若脏页占总物理内存10％以上，则触发flush把脏数据写回磁盘。

那么问题来了，假如flush之前系统突然宕机断电，数据全都在Buffer里，那么岂不是全丢了？

确实会这样，所以linux提供了fsync方法，调用fsync方法会立刻把Buffer的数据刷入磁盘中，只要积极调用这个方法，就可以最大限度地减少宕机断电导致数据丢失的损失。

顺带一提，linux提供了三种flush的方法：
> 1. sync：将所有修改过的块缓冲区排入写队列，然后就返回，他并不等待实际I/O操作结束。所以不要认为调用了sync函数，就觉得数据已安全的送到磁盘文件上，有可能会出现问题，但是sync函数是无法得知的。
> 2. fsync：与sync函数不同，fsync函数只对由文件描符filedes指定的单一文件起作用，强制与描述字fildes相连文件的所有修改过的数据（包括核内I/O缓冲区中的数据）传送到外部永久介质，即刷新fildes给出的文件的所有信息，并且等待写磁盘操作结束，然后返回。调用 fsync()的进程将阻塞直到设备报告传送已经完成。
> 3. fdatasync：fdatasync函数类似于fsync函数，但它只影响文件数据部分，强制传送用户已写出的数据至物理存储设备，不包括文件本身的特征数据。这样可以适当减少文件刷新时的数据传送量。除数据外，fdatasync还会同步更新文件的属性。

那么问题又来了，在fsync的过程中，万一系统突然宕机断电，会不会导致丢失一般数据，只落地一半数据？

很遗憾，这种情况是无法避免的。但是断电会导致事务提交失败，磁盘上的数据会回滚。
<font color="red">**（此处存疑）**</font>

## 4 mysql事务持久化实现

mysql实现事务的持久化面临哪些挑战？
1. 磁盘写入物理瓶颈。
2. 用户态切换到内核态的性能损耗。

要解决这两点，就要在数据落地之前先把数据准备好，还要减少用户态到内核态的频繁切换，这就要求先在内存中处理数据。

举个最常见的例子：转账。

![pic](https://brt-1303999354.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20210216140819.png)

首先修改在内存里面修改金额，因为要支持回滚，所以修改前的数据要放到一个地方存起来，这个地方就是undo log。

当执行回滚操作时，直接把undo log的覆盖回来就行。

在数据buffer的内容完成修改后，尝试写入磁盘，此时数据buffer的数据就会放入OS buffer，定期写入磁盘。数据落地的路径是：数据buffer -> OS buffer -> 硬盘。

### 4.1 为什么不直接调用fsync？

那么问题来了，修改数据之后，如果把数据直接刷到OS buffer，然后调用fsync，不就直接把数据都刷到硬盘上了吗？为什么还需要定期去写磁盘呢。

我认为有两个原因：
1. 一旦修改数据就允许调用fsync，那么会频繁导致用户态和内核态的切换。就算buffer里面只有一点点数据，也要调用会阻塞的fsync，那么效率就会很低，不如在后台一直异步同步效率高。
2. 从数据buffer -> OS buffer -> 硬盘，这是一个随机写的过程，我们已经知道随机写的效率很低，所以不应该频繁触发这种同步操作。

那问题来了，既然不能用fsync去落地，那怎么保证事务的持久化？

### 4.2 redo log

事务的持久化不就是为了保证数据不丢失吗，我们换个思路，要是数据丢了，我们也能将其找回来恢复，那不是也行得通吗？

这就是redolog的功能了：
1. 在修改数据buffer之前，把更新后的值写入到redo log中，备份起来。
2. redo log落地后，再去修改数据buffer的值。
3. 突然断电之后，数据buffer中的数据通过redo log的备份去恢复。

那么问题来了，你的redo log不是也要落地吗？那这个和我直接落地数据buffer里面的数据有什么区别呢？

### 4.3 redo log的落地方式

回答4.2的问题：
1. 数据buffer直接落地，磁盘是随机写，效率低。
2. redo log的落地，磁盘是顺序写，效率高很多。
3. redo log只能追加，不能修改，可以多个事务共享一个redo log，能极大提高写的效率。

其实，mysql高效的秘诀，就是通过redo log可以高效写的特点，允许数据buffer不同步落地磁盘。就算数据丢了，也可以拖过redo log找回来。

### 4.4 是不是用了redo log就不会丢数据呢？

不是，只是把压力转移到redo log的落地上。就算redo log是顺序写效率高，有时候也是会丢数据的，这个要看持久化策略。

> 0. 只写redo log，每1s落地一次，性能最高，数据一致性最差。mysql崩溃可能丢失1s的数据。 
> 1. 写redo log buffer同时落地，性能最差，一致性最高。
> 2. 写redo log buffer同时写入到os buffer，性能好，安全性高，只要OS不宕机就能保证数据一致性。

示意图：

![pic](https://brt-1303999354.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20210216151657.png)

数据使用哪种持久化方式要看应用具体场景：

> 0. 文章评论等场景。效率最高，丢了数据也没有太大关系。
> 1. 支付类场景。对数据一致性要求高。
> 2. 订单类场景。需要综合性能和落地。

### 4.5 为什么redo log可以使用顺序写？

之前不是说顺序写对文件有要求吗？redo log文件大小不可变化，写满了预留的空间怎么办？

这里就使用到LRU了，如果redo log写满，新的日志到来会从头开始复写。为了顺序写的高性能，必须付出相应的代价。

## 5 总结

1. 因为磁盘io的瓶颈，mysql使用内存作为缓存。
2. 数据buffer刷新到磁盘的过程，是一个随机写的过程。
3. mysql通过redo log顺序写的优势，来保证内存和磁盘的数据一致性。
4. redo log的刷盘策略，决定了mysql事务是强一致性，还是弱一致性。
5. 需要按照使用场景，对事务设置刷盘策略。
6. 这篇文件只是一个概念的科普，mysql有很复杂的机制，使用bin log和redo log保证事务持久性，之后继续详解。